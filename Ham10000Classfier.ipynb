{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "import keras\n",
    "from tensorflow import image\n",
    "from keras.models import Sequential \n",
    "from keras import layers\n",
    "from keras.layers import Conv2D, Dense, Activation, Dropout, Flatten\n",
    "import pathlib \n",
    "import os\n",
    "import shutil\n",
    "from shutil import move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/William/Desktop/Jupyter/HAM10000/'\n",
    "img_height = 450\n",
    "img_width = 600\n",
    "batch_size = 32\n",
    "input_shape = (450, 600, 3) #w, h, c? \n",
    "epochs = 50\n",
    "#train_ds = tf.keras.preprocessing.image_dataset_from_directory(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/Users/William/Desktop/Jupyter/HAM10000//HAM10000'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-9fd345f4c303>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/HAM10000_metadata.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mall_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/HAM10000'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/Users/William/Desktop/Jupyter/HAM10000//HAM10000'"
     ]
    }
   ],
   "source": [
    "os.chdir(data_dir)\n",
    "df = pd.read_csv(data_dir + '/HAM10000_metadata.csv')\n",
    "all_images = os.listdir(data_dir + '/HAM10000')\n",
    "\n",
    "for image in all_images:\n",
    "    skinType = df[df['image_id'] + '.jpg' == image]['dx']\n",
    "    skinType = str(list(skinType)[0])\n",
    "    if not os.path.exists(os.path.join(data_dir, skinType)):\n",
    "        os.mkdir(os.path.join(data_dir, skinType))\n",
    "    path_from = os.path.join(data_dir + '/HAM10000', image)\n",
    "    path_to = os.path.join(data_dir, skinType, image)\n",
    "    move(path_from, path_to)\n",
    "\n",
    "shutil.rmtree(data_dir + '/HAM10000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10015 files belonging to 7 classes.\n",
      "Using 8012 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir, \n",
    "    label_mode = 'categorical',\n",
    "    validation_split = .2, \n",
    "    subset = \"training\", \n",
    "    seed = 123, \n",
    "    image_size = (img_height, img_width), \n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10015 files belonging to 7 classes.\n",
      "Using 2003 files for validation.\n",
      "['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n"
     ]
    }
   ],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    label_mode = 'categorical',\n",
    "    validation_split = .2, \n",
    "    subset = \"validation\", \n",
    "    seed = 123, \n",
    "    image_size = (img_height, img_width), \n",
    "    batch_size = batch_size\n",
    ")\n",
    "print(test_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.experimental.preprocessing.Resizing(150, 200, interpolation = 'bilinear'))\n",
    "model.add(layers.experimental.preprocessing.Resizing(75, 100, interpolation = 'bilinear'))\n",
    "model.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape = input_shape))\n",
    "model.add(layers.Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(32, (3,3), padding = 'same', activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(64, (3,3), padding = 'same', activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(num_classes, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = .0005), loss = tf.keras.losses.CategoricalCrossentropy(), metrics = ['accuracy'])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "251/251 [==============================] - 67s 267ms/step - loss: 1.0635 - accuracy: 0.6651\n",
      "Epoch 2/50\n",
      "251/251 [==============================] - 67s 268ms/step - loss: 0.9247 - accuracy: 0.6755\n",
      "Epoch 3/50\n",
      "251/251 [==============================] - 67s 268ms/step - loss: 0.8832 - accuracy: 0.6838\n",
      "Epoch 4/50\n",
      "251/251 [==============================] - 67s 268ms/step - loss: 0.8472 - accuracy: 0.6862\n",
      "Epoch 5/50\n",
      "251/251 [==============================] - 68s 269ms/step - loss: 0.8107 - accuracy: 0.6966\n",
      "Epoch 6/50\n",
      "251/251 [==============================] - 68s 271ms/step - loss: 0.7814 - accuracy: 0.7066\n",
      "Epoch 7/50\n",
      "251/251 [==============================] - 68s 270ms/step - loss: 0.7779 - accuracy: 0.7184\n",
      "Epoch 8/50\n",
      "251/251 [==============================] - 68s 272ms/step - loss: 0.7452 - accuracy: 0.7238\n",
      "Epoch 9/50\n",
      "251/251 [==============================] - 68s 272ms/step - loss: 0.7322 - accuracy: 0.7245\n",
      "Epoch 10/50\n",
      "251/251 [==============================] - 69s 274ms/step - loss: 0.7260 - accuracy: 0.7307\n",
      "Epoch 11/50\n",
      "251/251 [==============================] - 68s 272ms/step - loss: 0.7031 - accuracy: 0.7385\n",
      "Epoch 12/50\n",
      "251/251 [==============================] - 68s 270ms/step - loss: 0.6870 - accuracy: 0.7469\n",
      "Epoch 13/50\n",
      "251/251 [==============================] - 68s 271ms/step - loss: 0.6745 - accuracy: 0.7485\n",
      "Epoch 14/50\n",
      "251/251 [==============================] - 68s 271ms/step - loss: 0.6665 - accuracy: 0.7509\n",
      "Epoch 15/50\n",
      "251/251 [==============================] - 69s 275ms/step - loss: 0.6477 - accuracy: 0.7600\n",
      "Epoch 16/50\n",
      "251/251 [==============================] - 69s 274ms/step - loss: 0.6435 - accuracy: 0.7619\n",
      "Epoch 17/50\n",
      "251/251 [==============================] - 68s 271ms/step - loss: 0.6285 - accuracy: 0.7622\n",
      "Epoch 18/50\n",
      "251/251 [==============================] - 68s 271ms/step - loss: 0.6171 - accuracy: 0.7614\n",
      "Epoch 19/50\n",
      "251/251 [==============================] - 68s 273ms/step - loss: 0.6015 - accuracy: 0.7747\n",
      "Epoch 20/50\n",
      "251/251 [==============================] - 68s 273ms/step - loss: 0.5939 - accuracy: 0.7758\n",
      "Epoch 21/50\n",
      "251/251 [==============================] - 68s 272ms/step - loss: 0.5763 - accuracy: 0.7848\n",
      "Epoch 22/50\n",
      "251/251 [==============================] - 68s 271ms/step - loss: 0.5674 - accuracy: 0.7871\n",
      "Epoch 23/50\n",
      "251/251 [==============================] - 68s 272ms/step - loss: 0.5541 - accuracy: 0.7863\n",
      "Epoch 24/50\n",
      "251/251 [==============================] - 68s 272ms/step - loss: 0.5450 - accuracy: 0.7907\n",
      "Epoch 25/50\n",
      "251/251 [==============================] - 68s 273ms/step - loss: 0.5412 - accuracy: 0.7937\n",
      "Epoch 26/50\n",
      "251/251 [==============================] - 68s 272ms/step - loss: 0.5271 - accuracy: 0.8003\n",
      "Epoch 27/50\n",
      "251/251 [==============================] - 68s 272ms/step - loss: 0.5176 - accuracy: 0.8030\n",
      "Epoch 28/50\n",
      "251/251 [==============================] - 69s 275ms/step - loss: 0.4963 - accuracy: 0.8023\n",
      "Epoch 29/50\n",
      "251/251 [==============================] - 69s 275ms/step - loss: 0.4902 - accuracy: 0.8092\n",
      "Epoch 30/50\n",
      "251/251 [==============================] - 69s 275ms/step - loss: 0.4788 - accuracy: 0.8154\n",
      "Epoch 31/50\n",
      "251/251 [==============================] - 70s 279ms/step - loss: 0.4694 - accuracy: 0.8190\n",
      "Epoch 32/50\n",
      "251/251 [==============================] - 70s 278ms/step - loss: 0.4519 - accuracy: 0.8240\n",
      "Epoch 33/50\n",
      "251/251 [==============================] - 69s 275ms/step - loss: 0.4408 - accuracy: 0.8301\n",
      "Epoch 34/50\n",
      "251/251 [==============================] - 70s 277ms/step - loss: 0.4337 - accuracy: 0.8309\n",
      "Epoch 35/50\n",
      "251/251 [==============================] - 69s 277ms/step - loss: 0.4152 - accuracy: 0.8387\n",
      "Epoch 36/50\n",
      "251/251 [==============================] - 70s 277ms/step - loss: 0.4155 - accuracy: 0.8414\n",
      "Epoch 37/50\n",
      "251/251 [==============================] - 70s 278ms/step - loss: 0.4057 - accuracy: 0.8464\n",
      "Epoch 38/50\n",
      "251/251 [==============================] - 70s 278ms/step - loss: 0.3919 - accuracy: 0.8464\n",
      "Epoch 39/50\n",
      "251/251 [==============================] - 71s 282ms/step - loss: 0.3764 - accuracy: 0.8535\n",
      "Epoch 40/50\n",
      "251/251 [==============================] - 71s 285ms/step - loss: 0.3684 - accuracy: 0.8494\n",
      "Epoch 41/50\n",
      "251/251 [==============================] - 71s 282ms/step - loss: 0.3604 - accuracy: 0.8565\n",
      "Epoch 42/50\n",
      "251/251 [==============================] - 69s 276ms/step - loss: 0.3472 - accuracy: 0.8605\n",
      "Epoch 43/50\n",
      "251/251 [==============================] - 70s 277ms/step - loss: 0.3564 - accuracy: 0.8562\n",
      "Epoch 44/50\n",
      "251/251 [==============================] - 70s 278ms/step - loss: 0.3299 - accuracy: 0.8672\n",
      "Epoch 45/50\n",
      "251/251 [==============================] - 68s 270ms/step - loss: 0.3259 - accuracy: 0.8682\n",
      "Epoch 46/50\n",
      "251/251 [==============================] - 68s 269ms/step - loss: 0.3185 - accuracy: 0.8742\n",
      "Epoch 47/50\n",
      "251/251 [==============================] - 68s 269ms/step - loss: 0.3082 - accuracy: 0.8744\n",
      "Epoch 48/50\n",
      "251/251 [==============================] - 68s 272ms/step - loss: 0.3008 - accuracy: 0.8789\n",
      "Epoch 49/50\n",
      "251/251 [==============================] - 68s 271ms/step - loss: 0.2923 - accuracy: 0.8864\n",
      "Epoch 50/50\n",
      "251/251 [==============================] - 68s 269ms/step - loss: 0.2895 - accuracy: 0.8875\n"
     ]
    }
   ],
   "source": [
    "#fitting our model to the training and validation dataset\n",
    "classifier = model.fit(\n",
    "    train_ds, \n",
    "    batch_size = batch_size, \n",
    "    epochs = epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 24s 377ms/step - loss: 1.0035 - accuracy: 0.7594\n"
     ]
    }
   ],
   "source": [
    "#evaluating our model on the test dataset\n",
    "evaluation = model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.confusion_matrix()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
